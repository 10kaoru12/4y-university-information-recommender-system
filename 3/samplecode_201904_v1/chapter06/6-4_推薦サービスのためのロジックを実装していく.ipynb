{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習手法を利用したロジックの実装\n",
    "\n",
    "### 準備\n",
    "\n",
    "機械学習手法を用いたリコメンドロジックを実装していくにあたって、今一度実行環境の情報を整理しておきます。\n",
    "またここでの作業はJupyter NotebookないしはIPython Consoleを利用した対話的操作による実行を想定しています。\n",
    "\n",
    "#### サービスの確認\n",
    "\n",
    "次のコマンドをターミナルから実行し、現在の稼働しているコンテナについての情報を取得しておきます。\n",
    "これらの値はユーザの実行環境ごとにことなるため、それぞれの設定についてそれぞれのプログラムの設定を書き換えるようにしてください。\n",
    "\n",
    "```\n",
    "$ docker-compose ps\n",
    "    Name                  Command               State            Ports          \n",
    "--------------------------------------------------------------------------------\n",
    "apps_api_1     hug -f app.py                    Up      0.0.0.0:32769->8000/tcp \n",
    "apps_mongo_1   docker-entrypoint.sh mongod      Up      0.0.0.0:32768->27017/tcp\n",
    "apps_ngrok_1   /entrypoint.sh                   Up      0.0.0.0:4040->4040/tcp  \n",
    "apps_web_1     flask run --host 0.0.0.0 - ...   Up      0.0.0.0:80->80/tcp    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの準備\n",
    "\n",
    "`web`コンテナの中から機械学習を利用するためのログデータを、手元の環境にコピーしておきましょう。\n",
    "次のコマンドをターミナルから実行し、ログデータを取得します。\n",
    "\n",
    "```sh\n",
    "$ cd apps/\n",
    "$ mkdir -p data/\n",
    "$ docker cp $(docker-compose ps -q web):/app/data/event.jsonl ./data/event.$(date +%Y-%m-%d).jsonl\n",
    "$ ls data/\n",
    "event.2019-02-19.jsonl\n",
    "$ wc data/event.2019-02-19.jsonl\n",
    "   3829  177324 2369199 data/event.2019-02-19.jsonl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習に利用するデータセットを準備していきましょう。\n",
    "\n",
    "サービスに利用しているMongoDBからは、機械学習のために利用する書籍に関する情報のデータセットを\n",
    "ログに関するデータからユーザのサービス上の振る舞いについてのデータセットが構築できます。\n",
    "\n",
    "#### MongoDBから書籍情報を取得する\n",
    "\n",
    "あらためてサービスで利用している書籍情報をMongoDBより取得し、操作の行いやすいデータフレームに保持します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>genre</th>\n",
       "      <th>price</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1406</td>\n",
       "      <td>1406</td>\n",
       "      <td>1406</td>\n",
       "      <td>1086.000000</td>\n",
       "      <td>1347</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>401</td>\n",
       "      <td>1390</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>将棋</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-04-01 00:00:00</td>\n",
       "      <td>マイナビBEST 天頂の囲碁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>486</td>\n",
       "      <td>13</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-06-19 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-30 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1799.273481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1519.928550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1231.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39960.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author  body genre         price      publication_day           title\n",
       "count    1406  1406  1406   1086.000000                 1347            1406\n",
       "unique    401  1390    11           NaN                  805            1405\n",
       "top                    将棋           NaN  2013-04-01 00:00:00  マイナビBEST 天頂の囲碁\n",
       "freq      486    13   577           NaN                    8               2\n",
       "first     NaN   NaN   NaN           NaN  2003-06-19 00:00:00             NaN\n",
       "last      NaN   NaN   NaN           NaN  2019-04-30 00:00:00             NaN\n",
       "mean      NaN   NaN   NaN   1799.273481                  NaN             NaN\n",
       "std       NaN   NaN   NaN   1519.928550                  NaN             NaN\n",
       "min       NaN   NaN   NaN    473.000000                  NaN             NaN\n",
       "25%       NaN   NaN   NaN   1231.000000                  NaN             NaN\n",
       "50%       NaN   NaN   NaN   1620.000000                  NaN             NaN\n",
       "75%       NaN   NaN   NaN   1800.000000                  NaN             NaN\n",
       "max       NaN   NaN   NaN  39960.000000                  NaN             NaN"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymongo\n",
    "\n",
    "# *\n",
    "# 以下の情報はdocker-composeの設定より各自書き換える\n",
    "# *  \n",
    "mongo_authority = \"0.0.0.0:32807\" \n",
    "\n",
    "client = pymongo.MongoClient(f\"mongodb://{mongo_authority}\")\n",
    "db = client[\"mynavi\"]\n",
    "\n",
    "df_books = pd.DataFrame(list(db[\"books\"].find()))\n",
    "df_books._id = df_books._id.astype(str)\n",
    "df_books = df_books.rename({\"_id\": \"record_id\"}, axis=1)\n",
    "df_books = df_books.set_index(\"record_id\")\n",
    "\n",
    "df_books.publication_day = pd.to_datetime(df_books.publication_day)\n",
    "df_books.crawled_at = pd.to_datetime(df_books.crawled_at, unit='ms')\n",
    "\n",
    "required_columns = ['author', 'body', 'genre', 'price', 'publication_day', 'title']\n",
    "df_books = df_books[required_columns]\n",
    "\n",
    "df_books.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ログデータを読み込む\n",
    "\n",
    "データフレームへのログ読み込みを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>user_id</th>\n",
       "      <th>record_id</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3829</td>\n",
       "      <td>3829</td>\n",
       "      <td>3829</td>\n",
       "      <td>2905</td>\n",
       "      <td>2905.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>1161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>load</td>\n",
       "      <td>DIV</td>\n",
       "      <td>c23b213a-d813-4ecf-aee9-aaafdada76af</td>\n",
       "      <td>5c7d6b299c22452f2509fb43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2773</td>\n",
       "      <td>2783</td>\n",
       "      <td>388</td>\n",
       "      <td>184</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       event target                               user_id  \\\n",
       "count   3829   3829                                  3829   \n",
       "unique     3      5                                    99   \n",
       "top     load    DIV  c23b213a-d813-4ecf-aee9-aaafdada76af   \n",
       "freq    2773   2783                                   388   \n",
       "mean     NaN    NaN                                   NaN   \n",
       "std      NaN    NaN                                   NaN   \n",
       "min      NaN    NaN                                   NaN   \n",
       "25%      NaN    NaN                                   NaN   \n",
       "50%      NaN    NaN                                   NaN   \n",
       "75%      NaN    NaN                                   NaN   \n",
       "max      NaN    NaN                                   NaN   \n",
       "\n",
       "                       record_id     position  \n",
       "count                       2905  2905.000000  \n",
       "unique                      1161          NaN  \n",
       "top     5c7d6b299c22452f2509fb43          NaN  \n",
       "freq                         184          NaN  \n",
       "mean                         NaN     0.984509  \n",
       "std                          NaN     0.816560  \n",
       "min                          NaN     0.000000  \n",
       "25%                          NaN     0.000000  \n",
       "50%                          NaN     1.000000  \n",
       "75%                          NaN     2.000000  \n",
       "max                          NaN     2.000000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ログデータの読み込み\n",
    "_df = pd.read_json('./apps/data/event.2019-02-19.jsonl', lines=True)\n",
    "_df = _df.join(_df.context.apply(pd.Series))\n",
    "_df.rename({'book_id': 'record_id'}, axis=1,inplace=True)\n",
    "df_logs = _df[[\n",
    "    \"event\",\n",
    "    \"target\",\n",
    "    \"user_id\",\n",
    "    \"record_id\",\n",
    "    \"neighbors\",\n",
    "    \"position\"\n",
    "]]\n",
    "\n",
    "df_logs.drop('neighbors', axis=1).describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習用のデータセットを構築する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### クリック率予測用のデータセットの構築\n",
    "\n",
    "書籍情報からクリック率を予測するモデルのためのデータセットを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click</th>\n",
       "      <th>load</th>\n",
       "      <th>p_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1161.000000</td>\n",
       "      <td>1161.000000</td>\n",
       "      <td>1161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.094746</td>\n",
       "      <td>2.388458</td>\n",
       "      <td>0.025237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.491810</td>\n",
       "      <td>4.420349</td>\n",
       "      <td>0.136290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             click         load      p_click\n",
       "count  1161.000000  1161.000000  1161.000000\n",
       "mean      0.094746     2.388458     0.025237\n",
       "std       1.491810     4.420349     0.136290\n",
       "min       0.000000     1.000000     0.000000\n",
       "25%       0.000000     1.000000     0.000000\n",
       "50%       0.000000     2.000000     0.000000\n",
       "75%       0.000000     3.000000     0.000000\n",
       "max      50.000000   133.000000     1.000000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各itemnのクリック数, ロード数, クリック率を算出する\n",
    "g = df_logs.groupby([\"event\", \"target\", \"record_id\"])\n",
    "df_agg = g.size()\n",
    "\n",
    "df_data = df_agg.loc[(\"click\", \"A\")].to_frame(\"click\")\n",
    "df_data = df_data.join(df_agg.loc[(\"load\", \"DIV\")].to_frame(\"load\"), how=\"outer\")\n",
    "df_data = df_data.fillna(0)\n",
    "df_data['p_click'] = df_data.click / df_data.load\n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_books.join(df_data)\n",
    "df1.load = df1.load.fillna(0)\n",
    "df1.p_click = df1.p_click.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'body', 'genre', 'price', 'publication_day', 'title', 'click',\n",
       "       'load', 'p_click'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### クリック率予測用のデータセットの構築\n",
    "\n",
    "２つの書籍情報からよりクリックされやすい情報を取得します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習用のパイプラインの構築\n",
    "\n",
    "学習/評価のための機械学習用のパイプラインを構築していきましょう。\n",
    "\n",
    "### テキスト処理に利用する形態素解析器のMeacbのTokenizer\n",
    "\n",
    "以前の章で構築した`sklearn`用のパイプラインをあらためて、ここでも利用します。\n",
    "\n",
    "### mecabのインストールの確認\n",
    "\n",
    "テキスト処理に必要なソフトウェアとして`mecab`を再度インストールしましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CentOS(SageMaker)上でのmecabのミドルウェアのセットアッップ\n",
    "\n",
    "```sh\n",
    "$ sudo yum update -y \n",
    "$ sudo rpm -ivh http://packages.groonga.org/centos/groonga-release-1.1.0-1.noarch.rpm\n",
    "$ sudo yum install mecab mecab-devel mecab-ipadic\n",
    "$ mecab-config --version\n",
    "0.996\n",
    "```\n",
    "\n",
    "```sh\n",
    "$ pip3 install \"mecab-python3==0.7\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996\n"
     ]
    }
   ],
   "source": [
    "! mecab-config --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearnのパイプライ処理を行うためのMecabの実装を行う\n",
    "import MeCab\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class Token:\n",
    "    \"\"\"MeCabのトークンを保持するクラス\"\"\"\n",
    "    def __init__(self, node):\n",
    "        # 表層形\n",
    "        self.surface = node.surface\n",
    "\n",
    "        features = node.feature.split(\",\")\n",
    "        # 品詞\n",
    "        self.part_of_speech = features[0]\n",
    "        # 基本形\n",
    "        self.base_form = features[6]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{}\\t{}\".format(self.surface, self.part_of_speech)\n",
    "\n",
    "\n",
    "class MeCabTokenize(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"MeCabを利用して形態素解析を行うクラス\"\"\"\n",
    "    def __init__(self, pos_keep_filters=[]):\n",
    "        # MeCabインスタンスの生成\n",
    "        self.tokenizer = MeCab.Tagger(\"-b 100000\")\n",
    "        # メモリの初期化周りでバグがあるため、一度解析することで回避\n",
    "        self.tokenizer.parse(\"init\")\n",
    "\n",
    "        # 前処理を手軽に行えるように、品詞フィルタを作る\n",
    "        self.pos_keep_filters = pos_keep_filters\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # scikit-learn互換のインターフェイス\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # scikit-learn互換のインターフェイス\n",
    "        docs = []\n",
    "        # 1文書ずつ処理する\n",
    "        for text in X:\n",
    "            words = []\n",
    "            # 文書内のテキストを改行でさらに文に分ける\n",
    "            for sentence in self.split_text_to_sentences(text):\n",
    "                # 対象の文を分かち書き\n",
    "                words.extend(self.wakati(sentence))\n",
    "            # 文書はスペース区切りで追加する\n",
    "            docs.append(\" \".join(words))\n",
    "        return docs\n",
    "\n",
    "    def split_text_to_sentences(self, text, delimiter=\"。\"):\n",
    "        return [t for t in text.replace(delimiter, delimiter + \"\\n\").splitlines() if t]\n",
    "\n",
    "    def wakati(self, text):\n",
    "        return [t.base_form for t in self.tokenize(text)]\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        tokens = []\n",
    "\n",
    "        node = self.tokenizer.parseToNode(text)\n",
    "        node = node.next\n",
    "        while node.next:\n",
    "            token = Token(node)\n",
    "            # 品詞フィルターを適用する\n",
    "            if token.part_of_speech in self.pos_keep_filters:\n",
    "                tokens.append(Token(node))\n",
    "            node = node.next\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのパイプラインの組み立て"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データフレーム向けのTransfomerの構築\n",
    "\n",
    "今回データセットはデータフレームを利用しています。\n",
    "データセットに関する様々な処理をデータフレーム上で行いやすいように、`sklearn`で必要となる\n",
    "Transfomerをここで構築していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DFColumnSelector\n",
    "\n",
    "`DFColumnSelector`は、入力のデータフレームから、特定のカラムを取り出すTransfomerです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DFColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaptedLabelEncoder\n",
    "パイプラインにカテゴリ変数を組み込む際にscikit-learnで用意されているsklearn.preprocessingは\n",
    "そのままではパイプライン処理に利用できません。\n",
    "そのため簡単なアダプターを用意し、パイプライン上でも使えるようにクラス定義しておきます。\n",
    "これによりカテゴリ変数をうまく組み込むことができるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class AdaptedLabelEncoder(LabelEncoder):\n",
    "\n",
    "    def fit_transform(self, y, *args, **kwargs):\n",
    "        return super().fit_transform(y).reshape(-1, 1)\n",
    "\n",
    "    def transform(self, y, *args, **kwargs):\n",
    "        return super().transform(y).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習のワークフローを組み立てる\n",
    "\n",
    "ここまでで機械学習モデルの構築に必要なパイプラインの下準備を行うことができました。\n",
    "データセットの分割等を経て、モデルを構築していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "keep_pos = [\"名詞\", \"形容詞\", \"動詞\"]\n",
    "feature_extractor_books = make_pipeline(\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"text_title_feature\", make_pipeline(\n",
    "            DFColumnSelector(column=\"title\"),\n",
    "            MeCabTokenize(pos_keep_filters=keep_pos),\n",
    "            TfidfVectorizer(min_df=3)\n",
    "        )),\n",
    "        (\"text_body_feature\", make_pipeline(\n",
    "            DFColumnSelector(column=\"body\"),\n",
    "            MeCabTokenize(pos_keep_filters=keep_pos),\n",
    "            TfidfVectorizer(min_df=3)\n",
    "        )),\n",
    "    ])\n",
    ")\n",
    "\n",
    "classifier_pipeline = make_pipeline(\n",
    "    feature_extractor_books,\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クリック率に対して予測を行う\n",
    "random_seed = 45\n",
    "param_grid = {\n",
    "    \"linearregression__fit_intercept\": [True, False],\n",
    "    \"pipeline__featureunion__text_body_feature__tfidfvectorizer__min_df\": range(1,3),\n",
    "    \"pipeline__featureunion__text_title_feature__tfidfvectorizer__min_df\": range(1,3),\n",
    "\n",
    "    # \"logisticregression__penalty\": ['l1', 'l2'],\n",
    "    # \"logisticregression__C\": [0.1, 0.01, 0.001],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(\"p_click\", axis=1)\n",
    "y = df1.p_click.astype(float)\n",
    "\n",
    "# データセットの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/10., random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1265, 8)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text_title_feature', Pipeline(memory=None,\n",
       "     steps=[('dfcolumnselector', DFColumnSelector(column='title')), ('mecabtokenize', MeCabTokenize(pos_keep_filters=['名詞', '形容詞', '動詞']... ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'linearregression__fit_intercept': [True, False], 'pipeline__featureunion__text_body_feature__tfidfvectorizer__min_df': range(1, 3), 'pipeline__featureunion__text_title_feature__tfidfvectorizer__min_df': range(1, 3)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(classifier_pipeline, param_grid, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後にテストデータにおいてモデルの評価を行ってみましょう。\n",
    "回帰の問題として考えた場合には、score関数は$R^2$決定係数により計算されます。\n",
    "このあたいは正負の数値をとり1に近いほど良いスコアとなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24396623237593576"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score = clf.score(X_test, y_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIサーバへのデプロイ\n",
    "\n",
    "ここまででクリック率を予測するという形で機械学習モデルの構築を行いました。\n",
    "ここからこのモデルをサービスに組込む作業を行なっていきます。\n",
    "\n",
    "機械学習を利用したモデルの場合、入力と出力の組み合わせを考えて\n",
    "サービスとして効率の良い選択肢を考えましょう。\n",
    "\n",
    "先ほど構築したモデルは、回帰のモデルで入力データに対してクリック率の予測するモデルです。\n",
    "この予測に利用する既存のコンテンツデータは不変的であるため、保持しているコンテンツに対して\n",
    "あらかじめ全てを用意しておきMongoDBからこれにアクセスすることで高速に機械学習結果を利用することができます。\n",
    "\n",
    "予測値だけ作ってしまえば、集計処理を行いAPI化する作業と同じになります。\n",
    "ここで作ったモデルは機械学習モデルでクリック率を予測するため、予測結果はクリック率になると思われたかもしれません。\n",
    "クリック率を予測するモデルを導入することでえられるメリットは、クリックのないもしくは\n",
    "データ自体がほとんど足りていないコンテンツに対しても予測することができる点です。\n",
    "新しい本が導入された場合においても予測値をモデルに組み込むことができます。\n",
    "この時の新しい本の何を参考にするかは、素性に使った情報です。ここではタイトルや説明文です。\n",
    "\n",
    "この時の予測性能は先ほどテストデータが参考になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作業手順としては次の通りになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.406000e+03\n",
       "mean     2.065827e+00\n",
       "std      1.215828e+01\n",
       "min     -2.180208e+01\n",
       "25%     -5.362827e-08\n",
       "50%      9.461026e-10\n",
       "75%      6.099919e-08\n",
       "max      1.000000e+02\n",
       "Name: p_click_pred, dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['p_click_pred'] = clf.predict(X) * 100\n",
    "df1.p_click_pred.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この時学習データに利用した事例についても予測を行ってしまっていることには注意してください。\n",
    "以下で生成したデータをモデルの評価用途に利用すると間違った比較を行ってしまいます。\n",
    "\n",
    "あとはこのデータをMongoDBへ格納し、APIから利用できるようにするだけです。\n",
    "次のようにしてMongoDBへの格納を進めましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_click</th>\n",
       "      <th>p_click_pred</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5c7d6c469c22452f2509fb61</th>\n",
       "      <td>0.5</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2019-03-06 00:55:02.114882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5c7d59e99c22452f2509f94a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.480778e-08</td>\n",
       "      <td>2019-03-06 00:55:02.114882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5c7d71259c22452f2509fbdd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.291788e-08</td>\n",
       "      <td>2019-03-06 00:55:02.114882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p_click  p_click_pred                  created_at\n",
       "record_id                                                                  \n",
       "5c7d6c469c22452f2509fb61      0.5  5.000000e+01  2019-03-06 00:55:02.114882\n",
       "5c7d59e99c22452f2509f94a      0.0 -1.480778e-08  2019-03-06 00:55:02.114882\n",
       "5c7d71259c22452f2509fbdd      0.0 -2.291788e-08  2019-03-06 00:55:02.114882"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "data = df1[[\"p_click\", \"p_click_pred\"]]\n",
    "data[\"created_at\"] = str(datetime.now())\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f52956e0988>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "# mongodbのホスト割り当ては実行時の環境に依存する。\n",
    "# 以下のコマンドを実行し、取得を行う\n",
    "# $ docker-compose port mongo 27017\n",
    "mongo_authority = \"0.0.0.0:32807\" \n",
    "\n",
    "client = pymongo.MongoClient(f\"mongodb://{mongo_authority}\")\n",
    "db = client[\"mynavi\"]\n",
    "\n",
    "# イチオシ用のコレクションを追加する\n",
    "# すでに存在す場合には以下で削除\n",
    "cname = \"ml_click\"\n",
    "db.drop_collection(cname) \n",
    "collection = db.create_collection(cname)\n",
    "\n",
    "records = data.reset_index().replace({'record_id': 'book_id'}).to_dict('records')\n",
    "collection.insert_many(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、APIとして公開しましょう。APIサーバに次の変更を加えます。\n",
    "\n",
    "```python\n",
    "def fetch_ml_ranked_items():\n",
    "    client = _build_mongodb_client()        \n",
    "    db = client[\"mynavi\"]    \n",
    "    collection = db[\"ml_click\"]\n",
    "    \n",
    "    items = list(collection.find().sort([\n",
    "        (\"date\", pymongo.DESCENDING), \n",
    "        (\"count\", pymongo.DESCENDING)]\n",
    "    ).limit(3))\n",
    "    \n",
    "    return [item[\"book_id\"] for item in items]    \n",
    "\n",
    "\n",
    "@hug.get(\"/items\")\n",
    "def api_ranking_by_ml_click():\n",
    "    # 各自の実行環境のMongoDB上で存在するIDを指定する\n",
    "    ids = merge_serieses_keeping_order(\n",
    "        fetch_ml_ranked_items(),\n",
    "        fetch_mongo_items(),        \n",
    "    )\n",
    "    ids = list(map(str, ids))\n",
    "    return {\n",
    "        \"data\": list(ids)[:3],\n",
    "        \"logic\": \"ml_click\"\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./apps/webapi/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./apps/webapi/app.py\n",
    "import hug\n",
    "import pymongo \n",
    "\n",
    "\n",
    "def _build_mongodb_client():\n",
    "    user = 'root'\n",
    "    password = 'set_yours_credential'\n",
    "    authority = \"mongo:27017\"\n",
    "    client = pymongo.MongoClient(f\"mongodb://{user}:{password}@{authority}\")\n",
    "    return client\n",
    "\n",
    "        \n",
    "def fetch_mongo_items():\n",
    "    client = _build_mongodb_client()    \n",
    "    \n",
    "    db = client[\"mynavi\"]    \n",
    "    collection = db[\"books\"]\n",
    "    \n",
    "    items = list(collection.aggregate([\n",
    "        {\"$project\": {\"_id\": 1}},\n",
    "        {\"$sample\": {\"size\": 3}},\n",
    "    ]))                 \n",
    "    return [item['_id'] for item in items]\n",
    "\n",
    "\n",
    "def fetch_pickup_items():\n",
    "    client = _build_mongodb_client()    \n",
    "    \n",
    "    db = client[\"mynavi\"]    \n",
    "    collection = db[\"pickup\"]\n",
    "    return [item[\"book_id\"] for item in collection.find({}, {\"_id\": 0, \"book_id\": 1})]    \n",
    "\n",
    "\n",
    "def merge_serieses_keeping_order(lhs_ids, rhs_ids):\n",
    "    from itertools import chain\n",
    "    seen = set()\n",
    "    for item in chain(lhs_ids, rhs_ids):\n",
    "        if item in seen:\n",
    "            continue\n",
    "        \n",
    "        seen.add(item)\n",
    "        yield item\n",
    "           \n",
    "\n",
    "@hug.get(\"/\")\n",
    "def api_example():\n",
    "    return \"WebAPIの開発\"\n",
    "\n",
    "\n",
    "@hug.get(\"/items\", versions=1)\n",
    "def api_random_ids():\n",
    "    # 各自の実行環境のMongoDB上で存在するIDを指定する\n",
    "    ids = fetch_mongo_items()\n",
    "    ids = list(map(str, ids))\n",
    "    return {\n",
    "        \"data\": ids,\n",
    "        \"logic\": \"random\"\n",
    "    }\n",
    "\n",
    "\n",
    "# 古いロジックにバージョン番号を与える\n",
    "@hug.get(\"/items\", versions=1)\n",
    "def api_random_ids_with_pickup():\n",
    "    # 各自の実行環境のMongoDB上で存在するIDを指定する\n",
    "    ids = merge_serieses_keeping_order(\n",
    "        fetch_pickup_items(),\n",
    "        fetch_mongo_items(),        \n",
    "    )\n",
    "    ids = list(map(str, ids))\n",
    "    return {\n",
    "        \"data\": list(ids)[:3],\n",
    "        \"logic\": \"random w/ pickup\"\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_ranked_items():\n",
    "    client = _build_mongodb_client()        \n",
    "    db = client[\"mynavi\"]    \n",
    "    collection = db[\"ranking_click\"]\n",
    "    \n",
    "    items = list(collection.find().sort([\n",
    "        (\"date\", pymongo.DESCENDING), \n",
    "        (\"count\", pymongo.DESCENDING)]\n",
    "    ).limit(3))\n",
    "    \n",
    "    return [item[\"book_id\"] for item in items]    \n",
    "\n",
    "\n",
    "@hug.get(\"/items\")\n",
    "def api_ranking_by_click():\n",
    "    # 各自の実行環境のMongoDB上で存在するIDを指定する\n",
    "    ids = merge_serieses_keeping_order(\n",
    "        fetch_ranked_items(),\n",
    "        fetch_mongo_items(),        \n",
    "    )\n",
    "    ids = list(map(str, ids))\n",
    "    return {\n",
    "        \"data\": list(ids)[:3],\n",
    "        \"logic\": \"ranking-click\"\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_ml_ranked_items():\n",
    "    client = _build_mongodb_client()        \n",
    "    db = client[\"mynavi\"]    \n",
    "    collection = db[\"ml_click\"]\n",
    "    \n",
    "    items = list(collection.find().sort([\n",
    "        (\"date\", pymongo.DESCENDING), \n",
    "        (\"count\", pymongo.DESCENDING)]\n",
    "    ).limit(3))\n",
    "    \n",
    "    return [item[\"book_id\"] for item in items]    \n",
    "\n",
    "\n",
    "@hug.get(\"/items\")\n",
    "def api_ranking_by_ml_click():\n",
    "    # 各自の実行環境のMongoDB上で存在するIDを指定する\n",
    "    ids = merge_serieses_keeping_order(\n",
    "        fetch_ml_ranked_items(),\n",
    "        fetch_mongo_items(),        \n",
    "    )\n",
    "    ids = list(map(str, ids))\n",
    "    return {\n",
    "        \"data\": list(ids)[:3],\n",
    "        \"logic\": \"ml_click\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "さて、ここまでで推薦サービスづくりを行ってきました。\n",
    "簡単なルールベースのロジックから集計処理、そして機械学習モデルを利用した事例までです。\n",
    "\n",
    "サービスとしてはひとつのシステムとしてつながりましたが、個々の精度としては\n",
    "ここまで作ってきたサービスとしてはまだまだ改善の余地があるでしょう。\n",
    "\n",
    "モデルのそもそもの精度やパイプラインの自動化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_chainer_p36",
   "language": "python",
   "name": "conda_chainer_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
